{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPfU1Qt4/ue0/Wbo+FUqJ8A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SPNmuZp9zUNw"},"outputs":[],"source":["import numpy as np\n","import nltk\n","import string\n","import random"]},{"cell_type":"code","source":["f = open('corpus.txt', 'r', errors = 'ignore')\n","raw_doc = f.read()\n","raw_doc = raw_doc.lower()\n","nltk.download('punkt') #punkt tokenizer\n","nltk.download('wordnet') #using wordnet dictionary\n","nltk.download('omw-1.4')\n","\n","sentence_tokens = nltk.sent_tokenize(raw_doc)\n","word_tokens = nltk.word_tokenize(raw_doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"FfHbDm2rzjQd","executionInfo":{"status":"error","timestamp":1668295154381,"user_tz":360,"elapsed":310,"user":{"displayName":"PluDeSpacio","userId":"11190090545490327221"}},"outputId":"d5fcb4b4-42fb-4245-e840-473aba121506"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-5ee7ff62a960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpus.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#punkt tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordnet'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#using wordnet dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'corpus.txt'"]}]},{"cell_type":"code","source":["word_tokens[:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-PYjl5z2uDE","executionInfo":{"status":"ok","timestamp":1656961877824,"user_tz":300,"elapsed":219,"user":{"displayName":"PluDeSpacio","userId":"11190090545490327221"}},"outputId":"8512402c-ddaa-4442-9bf9-1641edf2a183"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['manga', 'from']"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["lemmer = nltk.stem.WordNetLemmatizer()\n","def LemTokens(tokens):\n","  return [lemmer.lemmatize(token) for token in tokens]\n","remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n","def LemNormalize(text):\n","  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"],"metadata":{"id":"6F_3Uoim33nE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GREET_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\",)\n","GREET_RESP = [\"hi\", \"hey\", \"hi there\", \"hello\", \"sup\", \"how you doin'\"]\n","def greet(sentence):\n","  for word in sentence.split():\n","    if word.lower() in GREET_INPUTS:\n","      return random.choice(GREET_RESP)"],"metadata":{"id":"rNIlQWvU5PPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"aw4nfOjU53To"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def response(user_response):\n","  robo1_response = ''\n","  TfidfVec = TfidfVectorizer(tokenizer = LemNormalize,  stop_words = 'english')\n","  tfidf = TfidfVec.fit_transform(sentence_tokens)\n","  vals = cosine_similarity(tfidf[-1], tfidf)\n","  idx = vals.argsort()[0][-2]\n","  flat = vals.flatten()\n","  flat.sort()\n","  req_tfidf = flat[-2]\n","  if(req_tfidf == 0):\n","    robo1_response = robo1_response + \"I am sorry! I don't understand you\"\n","    return robo1_response\n","  else:\n","    robo1_response = robo1_response + sentence_tokens[idx]\n","    return robo1_response"],"metadata":{"id":"qUtuO-et9DFk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["flag = True\n","print(\"Bot: Hello.\")\n","while(flag == True):\n","  user_response = input()\n","  user_response = user_response.lower()\n","  if(user_response != \"bye\"):\n","    if(greet(user_response) != None):\n","      print(\"Bot: \" + greet(user_response))\n","    else:\n","      sentence_tokens.append(user_response)\n","      word_tokens = word_tokens + nltk.word_tokenize(user_response)\n","      final_words = list(set(word_tokens))\n","      print(\"Bot: \", end=\"\")\n","      print(response(user_response))\n","      sentence_tokens.remove(user_response)\n","  else:\n","    flag = False"],"metadata":{"id":"oYv94wQNa9I5"},"execution_count":null,"outputs":[]}]}